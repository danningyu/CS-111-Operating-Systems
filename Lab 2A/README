NAME: Danning Yu
EMAIL: danningyu@ucla.edu
ID: 305087992

Files included in this README:
lab2_add.c: A C source file for carrying out adding +1 and -1 to a shared global counter. The number of times to carry out this operation and the number of threads to do this operation can be specified with the --iterations and --threads options respectively, with the defaults being 1. The program can also be forced to yield right before critical sections via a --yield argument. Mutexes, spin locks, or atomic GCC functions can be enabled via the --sync argument. There are an equal number of add +1's and -1's, so theoretically the counter should be 0 if no data races occur.

SortedList.h: A header file supplied by the instructor containing the interface for a doubly linked list with a dummy node, containing operations to look up a node, insert a node, get the length of the list, and delete a node. Also contains the definition of a linked list node.

SortedList.c: A C source file containing my implementation of the 4 functions specified in the SortedList.h. The implementations also check for if the list was corrupted.

lab2_list.c: A C source file that uses the functions specified in SortedList.h and SortedList.c to insert and delete elements from a linked list in an analogous fashion to lab2_add, where every node added is eventually deleted. It also takes --iterations, --threads, and --sync arguments that behave the same as described in lab2_add except for the elimination of the atomic GCC function option, and the --yield argument now takes arguments to have it yield when inserting, looking up, and/or deleting a node.

lab2_add.gp: A gnuplot script for plotting the data generated by the Makefile test runs of the lab2_add program.

lab2_list.gp: A gnuplot script for plotting the data generated by the Makefile test runs of the lab2_list program.

lab2_add.csv: A comma-separated values file containing outputs of Makefile test runs for lab2_add with various combinations of thread, iteration, yield, and sync options.

lab2_list.csv: A comma-separated values file containing outputs of Makefile test runs for lab2-list with various combinations of thread, iteration, yield, and sync options.

lab2_add-1.png: Plot of iterations per thread vs number of threads for runs of lab2_add that run without failure.

lab2_add-2.png: Plot of cost per operation (ns) versus number of iterations for 2 and 8 threads, with and without yielding. Generated using data from lab2_add.

lab2_add-3.png: Plot of cost per operation (ns) versus number of iterations for only 1 thread without yields. Generated using data from lab2_add.

lab2_add-4.png: Plot of iterations per yield versus threads for runs of lab2_add with yield, and with either no synchronization, CAS, mutexes, or spinlocks. Only runs that succeeded are graphed. Generated using data from lab2_add.

lab2_add-5.png: Cost per operation vs number of threads for various synchronziation mechanisms: none, CAS, mutexes, spinlocks. Generated using data from lab2_add.

lab2_list-1.png: Cost per operation vs number of iterations, both raw values and adjusted for the fact that the program is using a linked list. Generated using data from lab2_list.

lab2_list-2.png: Number of successful iterations versus number of threads for yields occurring at various places (none, insert, delete, insert and lookup, lookup and delete). Only successful runs are plotted. Generated using data from lab2_list.

lab2_list-3.png: Number of successful iterations for various yield options and synchronization options (none, mutex, spinlock) for 12 threads. Generated using data from lab2_list.

lab2_list-4.png: Length adjusted time cost per operation versus number of threads for operations on a linked list with either mutex or spin-lock synchronization. Purpose is to see the effect of increasing numbers of threads on these protection mechanisms. Generated using data from lab2_list.

Makefile: A file containing the following targets:
	all: The default target, simply calls build

	build: a target that calls the lab2_add and lab2_list targets to build those programs.

	lab2_add: compiles lab2_add.c with -g for debugging and -pthread for using p_threads, and all warning switches turned on.

	lab2_list: compiles lab2_list.c with -g for debugging and -pthread for using p_threads, and all warning switches turned on.

	tests: target that first builds the executables using the build target and then runs tests that vary the number of threads, number of operations, yielding or not yielding, and syncing. All results are exported to .csv files (lab2_add.csv and lab2_list.csv).

	graphs: target that uses gnuplot along with the scripts lab2_add.gp and lab2_list.gp to create plots from the data in lab2_add.csv and lab2_list.csv.

	dist: target that runs the tests and then creates the graphs before making the submission tarball.

	clean: target that removes the executables (lab2_add, lab2_list) and tar files.

2.1.1:
It takes a lot of iterations before errors are seen because each thread is only adding or substracting a number, so it doesn't take very long to do. Thus, if the thread can finish doing it before another thread is spawned, no conflict will occur. With fewer iterations, threads can finish faster than another thread can be created.

2.1.2:
The --yield runs are much slower because every time sched_yield() is called, the thread is giving up control, and it is very likely that control is given to a different thread, and so the additional time goes towards context switches and the scheduler picking who to handle first. We also can no longer get per-operation timings because the sched_yield() could happen at any time, thus disrupting the thread, and the length of a context switch is also variable, so it is hard to account for how long it takes.

2.1.3:
The average cost per operation drops with the increasing number of iterations because a new thread is created and told to run for a specified number of iterations, so as the number of iterations increases, the cost of creating a thread is gradually amortized, and thus the time per operation gradually goes down. If we examine the plot, we notice that as hte number of iterations increases, the cost seems to decrease exponentially, and thus once the decrease is small compared to the increase iterations (aka the curve has mostly leveled out), we will know that we've reached the "correct" cost.

2.1.4:
The options perform similarly for low numbers of threads because with less threads, there is less contention for the same resource (the counter), so thus, the synchronization mechanisms kick in less often. However, as the number of threads increases, the synchronization mechanisms need to do more work to ensure race conditions do not occur, and as a result, the cost per operation increases.

2.2.1:
The Part 1 graph (adds) has the cost per operation mostly level out as the number of threads increases, while the Part 2 graph (linked list) has linear growth in the cost per operation as the number of threads increases. This makes sense, as adding is an O(1) operation, while operations on the linked list are O(n), and as we increased the # of threads, we increased the number of linked list elements, and all the threads are competing for a single shared resource: the linked list.

2.2.2:
Examining the graph, we can see that both curves are roughly linear as the number of threads increases, which makes sense and is explained above (see 2.2.1). However, the slope (steepness of the line) is greater for spin locks: at lower thread counts, spin locks are cheaper, while at higher thread counts, spin locks are more expensive (and the extra cost increases rapidly). This is because at a low number of threads, spin locks aren't spinning as often so not much time is wasted, while are high numbers of threads, there is a lot of contention for the linked list, so a large amount of time is wasted spinning (wasted CPU cycles). On the other hand, mutexes are put to sleep when they cannot acquire the resource, so they come with a more overhead but scale better when the number of threads increases.

Sources used for this project:
Alexandre Tiard's discussion slides
http://man7.org/linux/man-pages/man3/pthread_create.3.html
http://man7.org/linux/man-pages/man3/pthread_join.3.html
https://computing.llnl.gov/tutorials/pthreads/
http://man7.org/linux/man-pages/man2/clock_gettime.2.html
https://gcc.gnu.org/onlinedocs/gcc-4.4.3/gcc/Atomic-Builtins.html
https://linux.die.net/man/1/gnuplot
http://man7.org/linux/man-pages/man3/malloc.3.html
https://www.geeksforgeeks.org/mutex-lock-for-linux-thread-synchronization/
https://docs.oracle.com/cd/E26502_01/html/E35303/ggecq.html
https://linux.die.net/man/3/getopt_long
http://man7.org/linux/man-pages/man3/atexit.3.html